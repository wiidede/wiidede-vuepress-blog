(window.webpackJsonp=window.webpackJsonp||[]).push([[38],{462:function(t,s,a){"use strict";a.r(s);var n=a(12),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"深度学习笔记"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#深度学习笔记"}},[t._v("#")]),t._v(" 深度学习笔记")]),t._v(" "),a("h2",{attrs:{id:"一个最基础的例子"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一个最基础的例子"}},[t._v("#")]),t._v(" 一个最基础的例子")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("l0 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("units"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" input_shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \nmodel "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Sequential"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("l0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'mean_squared_error'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("tf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("optimizers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Adam"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nhistory "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("celsius_q"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fahrenheit_a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" epochs"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("500")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" verbose"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nmodel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br")])]),a("h2",{attrs:{id:"术语"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#术语"}},[t._v("#")]),t._v(" 术语：")]),t._v(" "),a("ul",[a("li",[t._v("**特征：**模型的输入")]),t._v(" "),a("li",[t._v("**样本：**用于训练流程的输入/输出对")]),t._v(" "),a("li",[t._v("**标签：**模型的输出")]),t._v(" "),a("li",[t._v("**层级：**神经网络中相互连接的节点集合。")]),t._v(" "),a("li",[t._v("**模型：**神经网络的表示法")]),t._v(" "),a("li",[t._v("**密集全连接层 (FC)：**一个层级中的每个节点都与上个层级中的每个节点相连。")]),t._v(" "),a("li",[t._v("**权重和偏差：**模型的内部变量")]),t._v(" "),a("li",[t._v("**损失：**期望输出和真实输出之间的差值")]),t._v(" "),a("li",[t._v("**MSE：**均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕。")]),t._v(" "),a("li",[t._v("**梯度下降法：**每次小幅调整内部变量，从而逐渐降低损失函数的算法。")]),t._v(" "),a("li",[t._v("**优化器：**梯度下降法的一种具体实现方法。（有很多算法。在这门课程中，我们将仅使用“Adam”优化器，它是 "),a("em",[t._v("ADAptive with Momentum")]),t._v(" 的简称，并且被视为最佳优化器。）")]),t._v(" "),a("li",[t._v("**学习速率：**梯度下降过程中的损失改进“步长”。")]),t._v(" "),a("li",[t._v("**批次：**在训练神经网络的过程中使用的一组样本。")]),t._v(" "),a("li",[t._v("**周期：**完全经过整个训练数据集一轮")]),t._v(" "),a("li",[t._v("**前向传播：**根据输入计算输出值")]),t._v(" "),a("li",[t._v("**反向传播：**根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层。")]),t._v(" "),a("li",[t._v("**扁平化：**将二维图像转换为一维向量的过程")]),t._v(" "),a("li",[t._v("**ReLU：**一种激活函数，使模型能够解决非线性问题")]),t._v(" "),a("li",[t._v("**Softmax：**一种函数，能够为每个潜在输出类别生成概率")]),t._v(" "),a("li",[t._v("**分类：**一种机器学习模型，用于区分两个或多个输出类别")])])])}),[],!1,null,null,null);s.default=e.exports}}]);