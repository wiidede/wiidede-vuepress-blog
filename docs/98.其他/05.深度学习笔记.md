---
title: 深度学习笔记
date: 2020-04-03 19:29:41
tags:
  - 深度学习
categories:
  - 其他
id: deep-learning-note
permalink: /deep-learning-note/
---

# 深度学习笔记

## 一个最基础的例子

```python
l0 = tf.keras.layers.Dense(units=1, input_shape=[1])
model = tf.keras.Sequential([l0])
model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))
history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)
model.predict([100.0])
```

## 术语：

- **特征：**模型的输入
- **样本：**用于训练流程的输入/输出对
- **标签：**模型的输出
- **层级：**神经网络中相互连接的节点集合。
- **模型：**神经网络的表示法
- **密集全连接层 (FC)：**一个层级中的每个节点都与上个层级中的每个节点相连。
- **权重和偏差：**模型的内部变量
- **损失：**期望输出和真实输出之间的差值
- **MSE：**均方误差，一种损失函数，它会将一小部分很大的差值视作比大量很小的差值更糟糕。
- **梯度下降法：**每次小幅调整内部变量，从而逐渐降低损失函数的算法。
- **优化器：**梯度下降法的一种具体实现方法。（有很多算法。在这门课程中，我们将仅使用“Adam”优化器，它是 *ADAptive with Momentum* 的简称，并且被视为最佳优化器。）
- **学习速率：**梯度下降过程中的损失改进“步长”。
- **批次：**在训练神经网络的过程中使用的一组样本。
- **周期：**完全经过整个训练数据集一轮
- **前向传播：**根据输入计算输出值
- **反向传播：**根据优化器算法计算内部变量的调整幅度，从输出层级开始，并往回计算每个层级，直到抵达输入层。
- **扁平化：**将二维图像转换为一维向量的过程
- **ReLU：**一种激活函数，使模型能够解决非线性问题
- **Softmax：**一种函数，能够为每个潜在输出类别生成概率
- **分类：**一种机器学习模型，用于区分两个或多个输出类别